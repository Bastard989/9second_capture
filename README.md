# 9second_capture

Статус: в разработке.

Локальный агент для записи встреч с компьютера пользователя: захват системного звука, транскрибация, аналитика и экспорт результатов. Работает на локальной машине и сохраняет все данные на диск пользователя.

## Идея работы агента

Пользователь устанавливает агент на свой ПК, запускает его одним кликом и получает локальный веб-интерфейс. Через него можно начать/остановить запись, проверить входной звук и скачать результаты. Никакие данные не уходят в облако без явного решения пользователя.

## Установка агента (для пользователя)

Ниже максимально простой сценарий для macOS (без терминальных тонкостей):

1) Откройте приложение `9second_capture.app`.
2) На стартовом экране нажмите `Полная установка (Whisper)` и дождитесь статуса `done`.
3) Установите Ollama и скачайте хотя бы одну модель (например `llama3.1:8b`).
4) Нажмите `Открыть UI`.
5) В блоке `Подключение` нажмите `Инструкция` и установите аудио‑драйвер под свою ОС.
6) В блоке `LLM модель` нажмите `Сканировать`, выберите модель и нажмите `Сменить модель`.
7) Нажмите `Проверить драйвер`, затем `Проверить захват`.
8) Нажмите `Старт`, дождитесь отсчёта 9 секунд, начните встречу.
9) После `Стоп` откройте `Результаты` и скачайте `raw/clean`, `TXT` или `Таблицу`.

Если после первого `Открыть UI` страница не открылась сразу:
- подождите 2–5 секунд и повторите `Открыть UI`;
- если не помогло, перезапустите приложение один раз.

### Установка через терминал (macOS, копировать и вставить)

Если репозиторий уже есть на компьютере:

```bash
cd "/Users/kirill/Documents/New project/9second_capture"
git pull
bash tools/packaging/build_mac.sh
open "/Users/kirill/Documents/New project/9second_capture/dist/9second_capture.app"
```

Если ставите с нуля:

```bash
cd "/Users/kirill/Documents/New project"
git clone https://github.com/Bastard989/9second_capture.git
cd "/Users/kirill/Documents/New project/9second_capture"
bash tools/packaging/build_mac.sh
open "/Users/kirill/Documents/New project/9second_capture/dist/9second_capture.app"
```

После открытия приложения:
1) Нажмите `Полная установка (Whisper)` и дождитесь `done`.
2) Нажмите `Открыть UI`.
3) Если UI не открылся с первого раза, подождите 2–5 секунд и нажмите `Открыть UI` ещё раз.

### Ollama и модели (macOS, копировать и вставить)

```bash
brew install --cask ollama
open -a Ollama
ollama pull llama3.1:8b
ollama list
```

Дополнительные модели (примеры):

```bash
ollama pull qwen2.5:7b
ollama pull mistral:7b
```

В UI:
1) `LLM модель` -> `Сканировать`
2) выбрать модель из списка
3) нажать `Сменить модель`

### Быстрая проверка перед звонком (2 минуты)

1) В UI выберите режим:
- `Системный звук` — для виртуального драйвера (BlackHole/VB-CABLE).
- `Экран + звук` — обязательно включите `Share audio` в окне выбора экрана.
2) В поле `Микрофон` оставьте `Авто (рекомендуется)` и не выбирайте виртуальный драйвер как микрофон.
3) Для `Экран + звук` оставьте чекбокс `Добавлять микрофон в запись` включенным.
4) Нажмите `Проверить захват` и убедитесь, что статус сигнала не `нет аудио`.
5) Нажмите `Старт`, скажите 1–2 фразы, нажмите `Стоп`.
6) В блоке `Результаты` выберите запись и нажмите `Скачать` (raw/clean) — в файле должен быть текст.

Если текст пустой:
- проверьте, что выбран правильный источник звука;
- для `Экран + звук` включите `Share audio`;
- для `Системный звук` убедитесь, что вывод встречи реально идет в виртуальный драйвер.
- убедитесь, что микрофон не совпадает с BlackHole/VB-CABLE (оставьте `Авто`).
- если `чанки` растут, а текста нет — в поток идёт тишина (не тот источник/нет loopback);
- нажмите `Проверить захват`: при рабочем потоке сигнал должен быть не `нет аудио`;
- для быстрого обходного теста переключитесь на `Экран + звук` и снова включите `Share audio`.

## Как это работает

1) Агент запускается и поднимает локальную страницу (127.0.0.1). Порт выбирается автоматически (свободный).
2) Пользователь проверяет доступность/наличие драйвера захвата звука.
3) После нажатия Start идёт отсчёт 9 секунд, затем начинается запись.
4) Агент захватывает системный звук (или fallback — захват экрана со звуком) и обрабатывает запись.
5) Во время записи LLM (по настройке) очищает текст и помогает определить, кто говорит.
6) По завершении формируются raw/clean транскрипты (raw от STT, clean после очистки/LLM).
7) По кнопке LLM формирует отчет (отдельно для raw/clean).
8) По кнопке LLM формирует структурированные табличные данные (CSV/JSON) отдельно для raw/clean.
9) Все результаты доступны для просмотра и скачивания по кнопке (без авто‑скачивания).
10) Дополнительно: можно загрузить конференцию как файл (аудио/видео) и прогнать через тот же пайплайн.

## Что сохраняется локально

- raw transcript (сырой текст, STT)
- clean transcript (очищенный текст, LLM по настройке)
- отчет (summary/analytics) — по кнопке LLM
- structured data (CSV/JSON) — по кнопке LLM, отдельно для raw и clean
- результаты хранятся локально в хранилище агента и доступны для просмотра/скачивания (без авто‑скачивания)

Схема структурированных данных: `docs/structured_schema.md`.

## Драйверы захвата звука

Системный звук требует виртуального аудио-драйвера. Мы оставляем установку драйвера на пользователе, а агент дает инструкцию и проверяет наличие сигнала. Если системный звук недоступен, возможен fallback через захват экрана со звуком.

### Инструкция по установке (по ОС)

macOS:
- Установить виртуальный драйвер захвата системного звука (например, BlackHole).
- В Audio MIDI Setup создать Multi‑Output Device (включить колонки + BlackHole).
- В UI агента выбрать BlackHole как источник входа.

Windows:
- Установить виртуальный кабель (например, VB‑CABLE).
- Переключить вывод системы на “CABLE Input”.
- В UI агента выбрать “CABLE Output” как источник входа.

Linux (PulseAudio / PipeWire):
- Убедиться, что доступен “Monitor of <device>” (loopback/monitor sink).
- В UI агента выбрать “Monitor of …” как источник входа.

Если драйвер недоступен, используем fallback через захват экрана со звуком.

## UI-логика (локальный веб-интерфейс)

Основные действия:
- Проверить наличие/доступность драйвера захвата звука
- Начать запись / Остановить запись (запись запускается через 9 секунд после нажатия Start)
- Загрузить конференцию как файл (аудио‑анализ работает)
- Загрузить конференцию как файл (видео‑анализ в разработке, нужен мультимодальный LLM)
- Просмотр и скачивание raw/clean транскриптов, отчёта и structured‑данных (по кнопке)
- Сформировать отчёт (raw/clean) по кнопке LLM
- Сформировать structured‑данные (raw/clean) по кнопке LLM
- Переключение языка RU/EN

## Дорожная карта (без сроков)

Принятые решения:
- Локальный агент + локальный web-интерфейс вместо полноразмерного GUI.
- Автовыбор свободного порта при старте (fallback по диапазону + запоминание удачного порта).
- Двухъязычный UI (RU/EN) с переключателем.
- Запись запускается только по кнопке (после 9-секундного отсчёта) и останавливается по кнопке.
- Драйверы захвата звука устанавливает пользователь; агент проверяет наличие/доступность драйвера.
- Результаты хранятся локально; скачивание — по кнопке (без авто‑скачивания).
- Structured данные формируются по кнопке после завершения встречи (raw/clean отдельно, экспорт CSV/JSON).
- Идентификация говорящих: ведущий представляется в начале; обращения по имени используются для сопоставления speaker‑кластеров.
- LLM работает в двух слоях:
- во время записи (очистка текста и определение говорящих)
- по кнопке (отчёт и табличные данные)
- Окно ответа после обращения по имени: 6–10 секунд (конфигурируемо).
- Если адресат не отвечает и явно упоминается отсутствие/ответ за него, ответ помечается как “proxy for <имя>”.

План развития:
1) Локальный режим записи + базовый UI (Старт/Стоп, статус, проверка звука, 9‑секундный отсчёт).
2) Локальные результаты и список записей (скачивание файлов).
3) Structured данные по кнопке (LLM) + экспорт CSV/JSON.
4) Лаунчер для macOS/Windows/Linux (иконка, автозапуск UI).
5) Полировка UX/инструкций/валидаций.
6) Опционально: режим синхронизации результатов с сервером (по желанию пользователя).

## Dev quickstart (для разработчиков)

- `docker compose up -d --build`
- Проверка API: `http://localhost:8010/health`
- Метрики: `http://localhost:8010/metrics`

### Тесты

Если при запуске тестов появляется ошибка про `python-multipart`, установи зависимости:
`pip install -r requirements.txt`.

## Документация

- `docs/user_guide.md` — краткая инструкция для пользователя.
- `docs/qa_checklist.md` — чеклист QA для локального агента.

## Локальный UI (агент)

Для локального web-интерфейса со стартом/стопом записи и проверкой сигнала:

- `AUTH_MODE=none STT_PROVIDER=whisper_local LLM_ENABLED=true LLM_LIVE_ENABLED=false OPENAI_API_BASE=http://127.0.0.1:11434/v1 OPENAI_API_KEY=ollama LLM_MODEL_ID=llama3.1:8b python3 scripts/run_local_agent.py`
- Скрипт сам выберет свободный порт в диапазоне `8010–8099` и запомнит его в `./data/local_agent/state.json`.
- UI откроется по адресу вида `http://127.0.0.1:<порт>`.

Важно:
- `run_local_agent.py` по умолчанию включает `QUEUE_MODE=inline` — локальная обработка без Redis/воркеров.
- Для локального качества/устойчивости по умолчанию используются:
  `WHISPER_MODEL_SIZE=medium`, `WHISPER_LANGUAGE=ru`, `WHISPER_BEAM_SIZE_LIVE=3`, `WHISPER_BEAM_SIZE_FINAL=6`,
  `WHISPER_WARMUP_ON_START=true`.
- Локальная БД — `sqlite` по пути `./data/local_agent/agent.db` (создаётся автоматически).
- Если нужен полный пайплайн через очереди, задай `QUEUE_MODE=redis` и подними зависимости
  (проще всего `docker compose up -d --build`).

LLM в локальном режиме:
- Для реального LLM без облака используйте Ollama (OpenAI-compatible API).
- Минимум: установить Ollama, подтянуть модель (например `ollama pull llama3.1:8b`), запустить сервис.
- Переменные: `OPENAI_API_BASE=http://127.0.0.1:11434/v1`, `OPENAI_API_KEY=ollama`, `LLM_MODEL_ID=llama3.1:8b`.
- В UI доступны кнопки `Сканировать` и `Сменить модель` (без перезапуска агента).
- Если локальный LLM недоступен, агент не падает: отчёт/structured переходят в fallback режим.

### Quick fallback recorder

В UI в блоке `Загрузка конференции` есть fallback-режим `Quick fallback запись`:
- принимает ссылку встречи и длительность;
- пишет системный звук сегментами;
- сохраняет `mp3` в `QUICK_RECORD_OUTPUT_DIR`;
- опционально делает локальную транскрибацию;
- опционально отправляет запись в `/v1` pipeline.

CLI-режим:
- `python3 scripts/quick_record_meeting.py --url "https://..." --duration-sec 900`
- или `make quick-record URL="https://..."`

Минимальный `.env` для старта:
- `APP_ENV=dev`
- `AUTH_MODE=api_key`
- `API_KEYS=dev-user-key`
- `SERVICE_API_KEYS=dev-service-key`
- `RECORDS_DIR=./data/records` (по умолчанию)

## Packaging (launcher)

Базовые инструкции по сборке бинарников: `tools/packaging/README.md`.
